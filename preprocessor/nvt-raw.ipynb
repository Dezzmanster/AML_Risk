{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 19 17:52:08 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.32.00    Driver Version: 455.32.00    CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:1C:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    39W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:1D:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    38W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import nvidia_smi\n",
    "\n",
    "# External Dependencies\n",
    "import cupy as cp\n",
    "import cudf\n",
    "import dask_cudf\n",
    "from dask_cuda import LocalCUDACluster\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "from dask.utils import parse_bytes\n",
    "from dask.delayed import delayed\n",
    "import dask.dataframe as dd\n",
    "import rmm\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# NVTabular\n",
    "import nvtabular as nvt\n",
    "import nvtabular.ops as ops\n",
    "from nvtabular.io import Shuffle\n",
    "from nvtabular.utils import device_mem_size\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home-credit-default-risk tables\n",
    "if not Path(\"data/application_test.csv\").is_file():\n",
    "    %cd data\n",
    "    ! wget https://www.dropbox.com/s/j9xwcj9ixki5t2l/home-credit-default-risk.zip?dl=0 -O data.zip\n",
    "    ! unzip -q data.zip\n",
    "    ! rm data.zip\n",
    "# default-of-credit-card-clients-dataset\n",
    "if not Path(\"data/default_ucr.csv\").is_file():\n",
    "    %cd data\n",
    "    ! wget https://www.dropbox.com/s/lj0d7qez18ea7dx/UCI_Credit_Card.csv?dl=0 -O default_ucr.csv\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the source datasets\n",
    "dict_ = {\n",
    "    'datasets':[\n",
    "                # default-of-credit-card-clients-datasets\n",
    "                pd.read_csv('./data/default_ucr.csv'),\n",
    "    ],\n",
    "\n",
    "    'name_dropped_columns':\n",
    "                [\n",
    "                 # default-of-credit-card-clients-datasets\n",
    "                 ['ID', 'default.payment.next.month']\n",
    "                 #['default.payment.next.month'] # 'ID' is needed for shuffling\n",
    "    ],   \n",
    "}\n",
    "\n",
    "# Keep ID and target columns separately\n",
    "dict_['dropped_columns'] = [dict_['datasets'][i][dict_['name_dropped_columns'][i]] for i in range(len(dict_['datasets']))]\n",
    "\n",
    "# Drop ID and target columns from the tables\n",
    "dict_['datasets'] = [dict_['datasets'][i].drop(dict_['name_dropped_columns'][i], axis=1) for i in range(len(dict_['datasets']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_D = 0\n",
    "X, X_rest = dict_['datasets'][N_D], dict_['dropped_columns'][N_D]\n",
    "\n",
    "#from fencoding_CPUs import FEncoding\n",
    "#f_dict = FEncoding().initialize_types(X, return_dtype=False)\n",
    "#f_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_replace_(self, X):\n",
    "    # TODO: dask realization is needed \n",
    "    def pars_date(x):\n",
    "        fmts = ('%Y', '%b %d, %Y','%b %d, %Y','%B %d, %Y','%B %d %Y','%m/%d/%Y','%m/%d/%y','%b %Y','%B%Y','%b %d,%Y', \n",
    "                  '%d.%m.%Y', '%Y.%m.%d', '%d-%m-%Y', '%Y-%m-%d %H:%M:%S')\n",
    "        t = True\n",
    "        if str(x.dtype) == 'object':\n",
    "            for fmt in fmts:\n",
    "                try:\n",
    "                    return pd.Series([dt.datetime.strptime(str(x.iloc[i]), fmt) for i in range(len(x))]).apply(lambda q: q.strftime('%m/%d/%Y')).astype('datetime64[ns]')\n",
    "                    t = False\n",
    "                    break \n",
    "                except ValueError:\n",
    "                    pass\n",
    "        if t and (len(str(x.iloc[0])) > 9) and (len(str(x.iloc[0])) <= 14): \n",
    "        # TODO: better condition on string to identify that it is unix timestep\n",
    "            try:\n",
    "                x = x.astype('float')\n",
    "                return pd.Series([dt.datetime.fromtimestamp(x.iloc[i]) for i in range(len(x))]).apply(lambda q: q.strftime('%m/%d/%Y')).astype('datetime64[ns]')\n",
    "            except ValueError:\n",
    "                pass\n",
    "    for column in X.columns:\n",
    "        x = pars_date(X[column])\n",
    "        try: \n",
    "            x.nunique()\n",
    "            X[column] = x\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FEncoding_advanced(object):   \n",
    "    def __init__(self, n_gpus=-1, device_spill_frac=0.8):    \n",
    "        '''\n",
    "        device_spill_frac: Spill GPU-Worker memory to host at this limit. Reduce if spilling fails to prevent device memory errors.\n",
    "        '''\n",
    "        global cliet, cluster\n",
    "        # Deploy a Single-Machine Multi-GPU Cluster\n",
    "        if n_gpus == -1:\n",
    "            nvidia_smi.nvmlInit()\n",
    "            n_gpus_avail = nvidia_smi.nvmlDeviceGetCount()\n",
    "            print('\\n n_gpus_avail: {}'.format(n_gpus_avail))\n",
    "            n_gpus = n_gpus_avail\n",
    "        # Delect devices to place workers\n",
    "        visible_devices = [i for i in list(range(n_gpus))]\n",
    "        visible_devices = str(visible_devices)[1:-1]\n",
    "        #print('visible_devices: {}'.format(visible_devices))\n",
    "        \n",
    "        \n",
    "        #TODO: how to reinitialzed cluster\n",
    "        cluster = LocalCUDACluster(\n",
    "            protocol = \"tcp\", # \"tcp\" or \"ucx\"\n",
    "            CUDA_VISIBLE_DEVICES = visible_devices,\n",
    "            device_memory_limit = device_spill_frac * device_mem_size(kind=\"total\"),\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            # Create the distributed client\n",
    "            client = Client(cluster)\n",
    "            display(client)\n",
    "            print('\\n Dashboard avail: http://localhost:8888/proxy/8787/status')\n",
    "            # Initialize RMM pool on ALL workers\n",
    "            def _rmm_pool():\n",
    "                rmm.reinitialize(\n",
    "                    pool_allocator=True,\n",
    "                    initial_pool_size=None, # Use default size\n",
    "                )         \n",
    "            client.run(_rmm_pool)  \n",
    "        \n",
    "        except MemoryError:\n",
    "            print('\\n The client is already initialized')\n",
    "        \n",
    "        self.n_gpus = n_gpus\n",
    "        self.client = client\n",
    "        self.output_path=\"./parquet_data_tmp\"\n",
    "        \n",
    "        # Regarding intialization part\n",
    "        self.categor_types = ['category', 'object', 'bool', 'int32', 'int64', 'int8']\n",
    "        self.numer_types = ['float', 'float32', 'float64']\n",
    "        self.time_types = ['datetime64[ns]', 'datetime64[ns, tz]'] \n",
    "        # What else? https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "        # TODO: check if there are any other time types\n",
    "        \n",
    "    def elim_empty_columns(self, X):\n",
    "        # GPU version\n",
    "        ddf = dd.from_pandas(X, npartitions=self.n_gpus)\n",
    "        cols_to_drop = []\n",
    "        for column in ddf.columns:\n",
    "            if len(ddf[column].unique().compute().values) < 2:\n",
    "                cols_to_drop.append(column)\n",
    "        print('\\n dropped columns:', cols_to_drop)\n",
    "        return ddf.drop(cols_to_drop, axis=1).compute()  \n",
    "    \n",
    "    def initialize_types(self, X, return_dtype=False):\n",
    "        self.categor_columns, self.numer_columns, self.time_columns = [], [], []\n",
    "        # Sometimes categorical feature can be presented with a float type. Let's check for that  \n",
    "        for column in X.columns:\n",
    "            c_type = str(X[column].dtype) \n",
    "            if any(c_type == t for t in self.numer_types):\n",
    "                unique_values = list(np.unique(X[column][~np.isnan(X[column])]))\n",
    "                if np.array([el.item().is_integer() for el in unique_values]).sum() == len(unique_values):\n",
    "                    #print('\\n {} has type {} and number of unique values: {}, will be considered as a categorical \\n'.format(column, c_type, len(unique_values)))\n",
    "                    #logging.info(f\"{column} has type {c_type} and number of unique values: {len(unique_values)}, will be considered as a categorical\")\n",
    "                    self.categor_columns.append(column)\n",
    "                else:\n",
    "                    self.numer_columns.append(column)\n",
    "            if any(c_type == t for t in self.categor_types):\n",
    "                self.categor_columns.append(column)\n",
    "            if any(c_type == t for t in self.time_types):\n",
    "                self.time_columns.append(column)                             \n",
    "        out_dict =  {'categor_columns': self.categor_columns,\n",
    "                'numer_columns': self.numer_columns,\n",
    "                'time_columns': self.time_columns,                    \n",
    "         }\n",
    "        if return_dtype:\n",
    "            out_dict.update(\n",
    "                {'categor_columns_dtypes': [str(X[self.categor_columns].dtypes.values[i]) for i in range(len(self.categor_columns))],\n",
    "                 'numer_columns_dtypes': [str(X[self.numer_columns].dtypes.values[i]) for i in range(len(self.numer_columns))],\n",
    "                 'time_columns_dtypes': [str(X[self.time_columns].dtypes.values[i]) for i in range(len(self.time_columns))],                    \n",
    "             })\n",
    "        return out_dict\n",
    "    \n",
    "    def nvtabular(self, X, filename = None):\n",
    "        f_dict = fencoding.initialize_types(X,  return_dtype=False)\n",
    "        dataset = nvt.Dataset(X)\n",
    "        \n",
    "        # Initalize our Workflow\n",
    "        workflow = nvt.Workflow(cat_names=self.categor_columns, \n",
    "                        cont_names=self.numer_columns,\n",
    "                        label_name=[],\n",
    "                        client=self.client\n",
    "                       )\n",
    "        \n",
    "        tmp_output_path=\"./parquet_data_tmp\"\n",
    "        \n",
    "        # Operators: https://nvidia.github.io/NVTabular/main/api/ops/index.html\n",
    "\n",
    "        workflow.add_preprocess(\n",
    "            #TODO: change in OutlDetect \n",
    "            ops.Clip(0, 10, columns=f_dict['categor_columns'])#min_value=None, max_value=None, columns=f_dict['numer_columns'], replace=True)\n",
    "\n",
    "            #TODO: change in encode_categor\n",
    "            #ops.TargetEncoding(cat_groups=f_dict['categor_columns'],\n",
    "             #                  cont_target=None),\n",
    "\n",
    "            #TODO: chenge in tree-based models, nana will be filled in with max values (or zeros)\n",
    "            #ops.FillMissing(fill_val=0, columns=f_dict['categor_columns'] + f_dict['numer_columns'], replace=True),\n",
    "        )\n",
    "\n",
    "        workflow.add_preprocess(\n",
    "            ops.Categorify(10)\n",
    "        )\n",
    "\n",
    "        #workflow.add_preprocess(\n",
    "        #    ops.FillMedian()#columns=f_dict['categor_columns'], preprocessing=True, replace=True)\n",
    "\n",
    "        #)\n",
    "        \n",
    "        \n",
    "        \n",
    "        workflow.finalize()\n",
    "        \n",
    "        workflow.apply(\n",
    "            dataset,\n",
    "             output_format=\"parquet\",\n",
    "             output_path=tmp_output_path,\n",
    "             shuffle=Shuffle.PER_WORKER,  # Shuffle algorithm\n",
    "             out_files_per_proc=8, # Number of output files per worker\n",
    "        )\n",
    "        files = glob.glob(tmp_output_path + \"/*.parquet\")\n",
    "        X_final = cudf.read_parquet(files[0])\n",
    "        for i in range(1, len(files)):    \n",
    "            X_final = X_final.append(cudf.read_parquet(files[i]))      \n",
    "        \n",
    "        # Delete temporary files\n",
    "        shutil.rmtree(tmp_output_path, ignore_errors=True)\n",
    "        shutil.rmtree('dask-worker-space', ignore_errors=True)\n",
    "        \n",
    "        if filename is not None: \n",
    "            X_final.to_csv('./data/' + filename, index=False)\n",
    "            \n",
    "        return X_final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " n_gpus_avail: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:44447</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>2</li>\n",
       "  <li><b>Cores: </b>2</li>\n",
       "  <li><b>Memory: </b>404.32 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:44447' processes=2 threads=2, memory=404.32 GB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Dashboard avail: http://localhost:8888/proxy/8787/status\n"
     ]
    }
   ],
   "source": [
    "fencoding = FEncoding_advanced()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " dropped columns: []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2682.0</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13559.0</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49291.0</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>35835.0</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>220000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>208365.0</td>\n",
       "      <td>88004.0</td>\n",
       "      <td>31237.0</td>\n",
       "      <td>15980.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>5003.0</td>\n",
       "      <td>3047.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3502.0</td>\n",
       "      <td>8979.0</td>\n",
       "      <td>5190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>3526.0</td>\n",
       "      <td>8998.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2758.0</td>\n",
       "      <td>20878.0</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>19357.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>76304.0</td>\n",
       "      <td>52774.0</td>\n",
       "      <td>11855.0</td>\n",
       "      <td>48944.0</td>\n",
       "      <td>85900.0</td>\n",
       "      <td>3409.0</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>52964.0</td>\n",
       "      <td>1804.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49764.0</td>\n",
       "      <td>36535.0</td>\n",
       "      <td>32428.0</td>\n",
       "      <td>15313.0</td>\n",
       "      <td>2078.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0        20000.0    2          2         1   24      2      2     -1     -1   \n",
       "1       120000.0    2          2         2   26     -1      2      0      0   \n",
       "2        90000.0    2          2         2   34      0      0      0      0   \n",
       "3        50000.0    2          2         1   37      0      0      0      0   \n",
       "4        50000.0    1          2         1   57     -1      0     -1      0   \n",
       "...          ...  ...        ...       ...  ...    ...    ...    ...    ...   \n",
       "29995   220000.0    1          3         1   39      0      0      0      0   \n",
       "29996   150000.0    1          3         2   43     -1     -1     -1     -1   \n",
       "29997    30000.0    1          2         2   37      4      3      2     -1   \n",
       "29998    80000.0    1          3         1   41      1     -1      0      0   \n",
       "29999    50000.0    1          2         1   46      0      0      0      0   \n",
       "\n",
       "       PAY_5  ...  BILL_AMT3  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  \\\n",
       "0         -2  ...      689.0        0.0        0.0        0.0       0.0   \n",
       "1          0  ...     2682.0     3272.0     3455.0     3261.0       0.0   \n",
       "2          0  ...    13559.0    14331.0    14948.0    15549.0    1518.0   \n",
       "3          0  ...    49291.0    28314.0    28959.0    29547.0    2000.0   \n",
       "4          0  ...    35835.0    20940.0    19146.0    19131.0    2000.0   \n",
       "...      ...  ...        ...        ...        ...        ...       ...   \n",
       "29995      0  ...   208365.0    88004.0    31237.0    15980.0    8500.0   \n",
       "29996      0  ...     3502.0     8979.0     5190.0        0.0    1837.0   \n",
       "29997      0  ...     2758.0    20878.0    20582.0    19357.0       0.0   \n",
       "29998      0  ...    76304.0    52774.0    11855.0    48944.0   85900.0   \n",
       "29999      0  ...    49764.0    36535.0    32428.0    15313.0    2078.0   \n",
       "\n",
       "       PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \n",
       "0         689.0       0.0       0.0       0.0       0.0  \n",
       "1        1000.0    1000.0    1000.0       0.0    2000.0  \n",
       "2        1500.0    1000.0    1000.0    1000.0    5000.0  \n",
       "3        2019.0    1200.0    1100.0    1069.0    1000.0  \n",
       "4       36681.0   10000.0    9000.0     689.0     679.0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "29995   20000.0    5003.0    3047.0    5000.0    1000.0  \n",
       "29996    3526.0    8998.0     129.0       0.0       0.0  \n",
       "29997       0.0   22000.0    4200.0    2000.0    3100.0  \n",
       "29998    3409.0    1178.0    1926.0   52964.0    1804.0  \n",
       "29999    1800.0    1430.0    1000.0    1000.0    1000.0  \n",
       "\n",
       "[30000 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fencoding.elim_empty_columns(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'categor_columns': ['LIMIT_BAL',\n",
       "  'SEX',\n",
       "  'EDUCATION',\n",
       "  'MARRIAGE',\n",
       "  'AGE',\n",
       "  'PAY_0',\n",
       "  'PAY_2',\n",
       "  'PAY_3',\n",
       "  'PAY_4',\n",
       "  'PAY_5',\n",
       "  'PAY_6',\n",
       "  'BILL_AMT1',\n",
       "  'BILL_AMT2',\n",
       "  'BILL_AMT3',\n",
       "  'BILL_AMT4',\n",
       "  'BILL_AMT5',\n",
       "  'BILL_AMT6',\n",
       "  'PAY_AMT1',\n",
       "  'PAY_AMT2',\n",
       "  'PAY_AMT3',\n",
       "  'PAY_AMT4',\n",
       "  'PAY_AMT5',\n",
       "  'PAY_AMT6'],\n",
       " 'numer_columns': [],\n",
       " 'time_columns': [],\n",
       " 'categor_columns_dtypes': ['float64',\n",
       "  'int64',\n",
       "  'int64',\n",
       "  'int64',\n",
       "  'int64',\n",
       "  'int64',\n",
       "  'int64',\n",
       "  'int64',\n",
       "  'int64',\n",
       "  'int64',\n",
       "  'int64',\n",
       "  'float64',\n",
       "  'float64',\n",
       "  'float64',\n",
       "  'float64',\n",
       "  'float64',\n",
       "  'float64',\n",
       "  'float64',\n",
       "  'float64',\n",
       "  'float64',\n",
       "  'float64',\n",
       "  'float64',\n",
       "  'float64'],\n",
       " 'numer_columns_dtypes': [],\n",
       " 'time_columns_dtypes': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fencoding.initialize_types(X, return_dtype=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fencoding.nvtabular(X, filename = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
